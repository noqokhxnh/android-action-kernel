import os
import time
import subprocess
import json
from typing import Dict, Any, List  # Th√™m List v√†o ƒë√¢y
from dotenv import load_dotenv

import google.generativeai as genai
import sanitizer

# --- CONFIGURATION ---
load_dotenv()
ADB_PATH = "adb"  
MODEL_NAME = "gemini-2.5-flash"  
SCREEN_DUMP_PATH = "/sdcard/window_dump.xml"
LOCAL_DUMP_PATH = "window_dump.xml"


# C·∫•u h√¨nh API Key
api_key = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=api_key)
model = genai.GenerativeModel(MODEL_NAME)

def run_adb_command(command: List[str]):
    """Executes a shell command via ADB."""
    result = subprocess.run([ADB_PATH] + command, capture_output=True, text=True)
    if result.stderr and "error" in result.stderr.lower():
        print(f"‚ùå ADB Error: {result.stderr.strip()}")
    return result.stdout.strip()

def get_screen_state() -> str:
    """Dumps the current UI XML and returns the sanitized JSON string."""
    run_adb_command(["shell", "uiautomator", "dump", SCREEN_DUMP_PATH])
    run_adb_command(["pull", SCREEN_DUMP_PATH, LOCAL_DUMP_PATH])
    
    if not os.path.exists(LOCAL_DUMP_PATH):
        return "Error: Could not capture screen."
        
    with open(LOCAL_DUMP_PATH, "r", encoding="utf-8") as f:
        xml_content = f.read()
        
    elements = sanitizer.get_interactive_elements(xml_content)
    return json.dumps(elements, indent=2)

def execute_action(action: Dict[str, Any]):
    """Executes the action decided by the LLM."""
    act_type = action.get("action")
    
    if act_type == "tap":
        coords = action.get("coordinates")
        if coords:
            x, y = coords
            print(f"üëâ Tapping: ({x}, {y})")
            run_adb_command(["shell", "input", "tap", str(x), str(y)])
        
    elif act_type == "type":
        text = action.get("text", "").replace(" ", "%s")
        print(f"‚å®Ô∏è Typing: {action.get('text')}")
        run_adb_command(["shell", "input", "text", text])
        
    elif act_type == "home":
        print("üè† Going Home")
        run_adb_command(["shell", "input", "keyevent", "3"]) # M√£ 3 l√† Home
        
    elif act_type == "back":
        print("üîô Going Back")
        run_adb_command(["shell", "input", "keyevent", "4"]) # M√£ 4 l√† Back
        
    elif act_type == "wait":
        print("‚è≥ Waiting...")
        time.sleep(2)
        
    elif act_type == "done":
        print("‚úÖ Goal Achieved.")
        exit(0)

def get_llm_decision(goal: str, screen_context: str) -> Dict[str, Any]:
    """Sends screen context to Gemini and asks for the next move."""
    prompt = f"""
    You are an Android Driver Agent. Output ONLY a valid JSON object.
    
    GOAL: {goal}
    SCREEN_CONTEXT:
    {screen_context}

    Available Actions:
    - {{"action": "tap", "coordinates": [x, y], "reason": "..."}}
    - {{"action": "type", "text": "...", "reason": "..."}}
    - {{"action": "home", "reason": "..."}}
    - {{"action": "back", "reason": "..."}}
    - {{"action": "wait", "reason": "..."}}
    - {{"action": "done", "reason": "..."}}
    """
    
    # C√∫ ph√°p chu·∫©n c·ªßa Gemini SDK
    response = model.generate_content(
        prompt,
        generation_config={"response_mime_type": "application/json"}
    )
    
    return json.loads(response.text)

def run_agent(goal: str, max_steps=10):
    print(f"üöÄ Android Use Agent Started. Goal: {goal}")
    for step in range(max_steps):
        print(f"\n--- Step {step + 1} ---")
        print("üëÄ Scanning Screen...")
        screen_context = get_screen_state()
        
        print("üß† Thinking...")
        try:
            decision = get_llm_decision(goal, screen_context)
            print(f"üí° Decision: {decision.get('reason')}")
            execute_action(decision)
        except Exception as e:
            print(f"‚ùå Error during decision/action: {e}")
        
        time.sleep(2)

if __name__ == "__main__":
    GOAL = input("Enter your goal: ")
    run_agent(GOAL)